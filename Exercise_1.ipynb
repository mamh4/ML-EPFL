{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand, randn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK A: Matrix standardisation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.74058808  1.7280553  -0.90453403]\n",
      " [-1.09478239 -0.67202151 -0.90453403]\n",
      " [ 1.22358031 -0.57601843  0.30151134]\n",
      " [-0.86938601 -0.48001536  1.50755672]]\n",
      "[[ 0.74058808  1.7280553  -0.90453403]\n",
      " [-1.09478239 -0.67202151 -0.90453403]\n",
      " [ 1.22358031 -0.57601843  0.30151134]\n",
      " [-0.86938601 -0.48001536  1.50755672]]\n"
     ]
    }
   ],
   "source": [
    "def normalise(matrix):\n",
    "    result = np.zeros(matrix.shape) # careful to make a copy!\n",
    "    matrix = matrix.astype(float)  # Convert the matrix to float data type\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            result[i, j] = (matrix[i, j] - np.mean(matrix[:, j])) / np.std(matrix[:, j])\n",
    "    return result\n",
    "\n",
    "#Vectorized version subtracts vectors from matrices using broadcasting\n",
    "def normalise_vectorized(matrix):\n",
    "    column_means = np.mean(matrix, axis=0)\n",
    "    column_std = np.std(matrix, axis=0)\n",
    "    standardized_matrix = (matrix - column_means) / column_std\n",
    "    return standardized_matrix\n",
    "\n",
    "# Example usage\n",
    "myMatrix = np.array([[80, 77, 3], [23, 2, 3], [95, 5, 6], [30, 8, 9]])\n",
    "print(normalise(myMatrix))\n",
    "print(normalise_vectorized(myMatrix))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: Eucliden Distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.41421356,  4.47213595,  8.94427191, 26.87005769],\n",
       "       [ 1.41421356,  2.        ,  6.32455532, 24.04163056],\n",
       "       [ 4.24264069,  2.        ,  4.        , 21.21320344]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myMatrixA = np.array([[1,2],[3,4],[5,6]])\n",
    "myMatrixB = np.array([[2,3],[5,4],[9,6],[20,21]])\n",
    "\n",
    "#Euclidean Distance\n",
    "def euclideanDistance(matrixA, matrixB):\n",
    "    distance = np.zeros((matrixA.shape[0], matrixB.shape[0]))\n",
    "    for i in range(matrixA.shape[0]):\n",
    "        for j in range(matrixB.shape[0]):\n",
    "            distance[i,j] = np.sqrt(np.sum(np.square(matrixA[i] - matrixB[j])))\n",
    "    return distance\n",
    "\n",
    "euclideanDistance(myMatrixA, myMatrixB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C: Likelihood of a data sample under a Gaussian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp/ipykernel_11156/3248152772.py:6: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return 1 / (2 * np.pi)**(len(mu)/2) * 1 / np.sqrt(np.linalg.det(sigma)) * np.exp(-1/2 * np.dot(np.dot((x - mu).T, np.linalg.inv(sigma)), (x - mu)))\n",
      "C:\\Users\\moham\\AppData\\Local\\Temp/ipykernel_11156/3248152772.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (2 * np.pi)**(len(mu)/2) * 1 / np.sqrt(np.linalg.det(sigma)) * np.exp(-1/2 * np.dot(np.dot((x - mu).T, np.linalg.inv(sigma)), (x - mu)))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_1 = (2,3)\n",
    "model_2 = (3,4)\n",
    "\n",
    "myMatrixA = np.array([[3,2],[3,2],[0,6]])\n",
    "def multivariate_normal_pdf(mu,sigma,x):\n",
    "    return 1 / (2 * np.pi)**(len(mu)/2) * 1 / np.sqrt(np.linalg.det(sigma)) * np.exp(-1/2 * np.dot(np.dot((x - mu).T, np.linalg.inv(sigma)), (x - mu)))\n",
    "\n",
    "print(multivariate_normal_pdf(np.mean(myMatrixA, axis=0), np.cov(myMatrixA.T), np.array([1,2])))\n",
    "\n",
    "def gaussian_classify(data, model_1,model_2):\n",
    "    \n",
    "    result = np.array\n",
    "    #First we compute the vector mu\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.cov(data.T)\n",
    "\n",
    "    #Likihood of the data given the model\n",
    "    #model_1_prob = np.multivariate_normal.pdf(data, mean=model_1[0], cov=model_1[1])\n",
    "    #model_2_prob = np.multivariate_normal.pdf(data, mean=model_2[0], cov=model_2[1])\n",
    "\n",
    "    #return np.linalg.det(sigma)\n",
    "\n",
    "\n",
    "\n",
    "#print(gaussian_classify(myMatrixA, model_1, model_2))\n",
    "\n",
    "#np.linalg.det(myMatrixA)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF value: 0.06794114034470018\n",
      "[0.26541827 0.26958986 0.30208302 0.23773875 0.20121529]\n",
      "[[ 1.34696746e-02  8.25401038e-03 -5.89112022e-03 -1.87510744e-03\n",
      "   1.98400606e-03]\n",
      " [ 8.25401038e-03  2.05968681e-02  1.95016003e-03  5.13469229e-05\n",
      "   9.49667704e-03]\n",
      " [-5.89112022e-03  1.95016003e-03  1.12095266e-02  8.36871607e-03\n",
      "  -3.00219346e-03]\n",
      " [-1.87510744e-03  5.13469229e-05  8.36871607e-03  2.15117542e-02\n",
      "  -8.45532548e-03]\n",
      " [ 1.98400606e-03  9.49667704e-03 -3.00219346e-03 -8.45532548e-03\n",
      "   1.96966587e-02]]\n",
      "True\n",
      "690.5937500228486\n",
      "0.6994207043965714\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "\n",
    "\n",
    "def multivariate_normal_cdf(mu, sigma, x):\n",
    "    \"\"\"\n",
    "    Compute the cumulative distribution function (CDF) of a multivariate Gaussian distribution.\n",
    "\n",
    "    Parameters:\n",
    "        mu (array): Mean vector of the distribution.\n",
    "        sigma (array): Covariance matrix of the distribution.\n",
    "        x (array): Point(s) at which to evaluate the CDF.\n",
    "\n",
    "    Returns:\n",
    "        cdf (float or array): CDF value(s) at the given point(s).\n",
    "    \"\"\"\n",
    "    dist = sp.multivariate_normal(mean=mu, cov=sigma)\n",
    "    cdf = dist.cdf(x)\n",
    "    return cdf\n",
    "\n",
    "\n",
    "\n",
    "# Define the mean vector and covariance matrix\n",
    "mu = np.array([1, 2])\n",
    "sigma = np.array([[2, 0.5], [0.5, 1]])\n",
    "\n",
    "# Define an input vector\n",
    "x = np.array([2, 3])\n",
    "\n",
    "# Calculate the PDF\n",
    "pdf_value = multivariate_normal_pdf(mu, sigma, x)\n",
    "\n",
    "# Print the result\n",
    "print(\"PDF value:\", pdf_value)\n",
    "\n",
    "np.random.seed(20)\n",
    "\n",
    "X = rand(10,5) #Matrix of n x d\n",
    "mu = np.mean(X, axis=0) #Vector of d\n",
    "sigma = np.cov(X.T) #Matrix of d x d # sysmmetric matrix\n",
    "\n",
    "model_1_mu = np.mean(X*0.5, axis=0)\n",
    "model_1_sigma = np.cov(X.T*0.5)\n",
    "\n",
    "model_2_mu = np.mean(X*-0.5, axis=0)\n",
    "model_2_sigma = np.cov(X.T*-0.5)\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) >= 0)\n",
    "\n",
    "print(model_1_mu)\n",
    "print(model_1_sigma)\n",
    "print(is_pos_def(model_1_sigma))\n",
    "print(multivariate_normal_pdf(model_1_mu, model_1_sigma, np.array([0.26,0.26,0.3,0.2,0.2])))\n",
    "print(multivariate_normal_cdf(model_1_mu, model_1_sigma, np.array([0.5,0.7,0.9,0.8,0.28])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.69872366, 0.75176984]), array([0.25997411, 0.14504062])]\n",
      "[[0.01764816 0.        ]\n",
      " [0.         0.06360523]]\n",
      "[[0.01764816 0.        ]\n",
      " [0.         0.06360523]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n, d, k = 100, 2, 2\n",
    "np.random.seed(20)\n",
    "X = rand(n, d)\n",
    "#print(X)\n",
    "means = [rand(d) * 0.5 + 0.5 , - rand(d)  * 0.5 + 0.5]  # mean for first model and second model| Basically here we make the mean not so far away \n",
    "#from our random data X we generated, note that X is comprised of two Gaussian vectors of n = 100 .i.e we have two gaussian distributions (bivariate)\n",
    "#later we can even plot it\n",
    "print(means)\n",
    "\n",
    "S = np.diag(rand(d))\n",
    "print(S)\n",
    "\n",
    "\n",
    "sigmas = [S]*k # This is the sigma of the first model and the second model\n",
    "print(sigmas[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we basically have 2 Random Gaussian vectors $\\in R^{100}$ We put them in matrix $X$ that is in our case $X \\in R^{100\\times 2}$\n",
    "\n",
    "Note: In theory this is actually $X^T$ as $X \\in R^{2\\times100}$\n",
    "\n",
    "We also have two Models that are not far off from the original data (This only serves for visualisation purposes, but in reality they need not depend on the data at all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,100) and (2,2) not aligned: 100 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11156/467753122.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#print(log_ps[0] > log_ps[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#print(means[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmultivariate_normal_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11156/3248152772.py\u001b[0m in \u001b[0;36mmultivariate_normal_pdf\u001b[1;34m(mu, sigma, x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmyMatrixA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmultivariate_normal_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmultivariate_normal_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyMatrixA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyMatrixA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,100) and (2,2) not aligned: 100 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "def compute_log_p(X, mean, sigma):\n",
    "    d = X.shape[1]\n",
    "    dxm = X - mean\n",
    "    exponent = -0.5 * np.sum(dxm * np.dot(dxm, np.linalg.inv(sigma)), axis=1)\n",
    "    return exponent - np.log(2 * np.pi) * (d / 2) - 0.5 * np.log(np.linalg.det(sigma))\n",
    "\n",
    "#log_ps = [compute_log_p(X, m, s) for m, s in zip(means, sigmas)]  # exercise: try to do this without looping\n",
    "\n",
    "#print(log_ps[0])\n",
    "#print(log_ps[1])\n",
    "\n",
    "#print(log_ps[0] > log_ps[1])\n",
    "#print(means[1])\n",
    "multivariate_normal_pdf(means[0], sigmas[0], X)\n",
    "means[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
